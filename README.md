## Project Summary

This website detects the top 3 most likely emotions that a user is feeling, based off the facial expressions they make into the computer's camera.

## Features Included

- Camera access & live video feed
- API call to face-api.js to detect the user's face & put a bounding box around it
- Expression recognition & corresponding emojis to represent these expressions
- Technical Details: Next.js, Tailwind CSS, TypeScript

## Time Spent on the Project

I spent roughly 4-5 hours on the project. It took me around 1 hour to initialize my project & build out the front end, 2 hours to integrate the camera and figure out how to call the API to recognize the user's face & emojis, and another 2-3 to debug.

## Running the Project
The website is accessible here: https://face-emoji-identification-amgn.vercel.app/.
